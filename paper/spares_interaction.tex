\documentclass[11pt]{article}

\usepackage{array}
\usepackage{clrscode3e}
\usepackage{amsmath}
\usepackage{kbordermatrix}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\begin{document}

\title{Efficient Calculation of Interaction Features on Sparse Matrices}
\author{Andrew Nystrom}
\date{}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
FILL THIS IN
\end{abstract}

\section{Introduction}

Introduction
Interaction features are a way of capturing correlations between features in a machine 
learning setting. A feature vector $\vec{x}$ of dimensionality $D$ has second degree interaction features 
$\{x_i \cdot x_j : i, j \in \{0,1,..., D-1\} \land i < j\}$, 
so a $D$ dimensional vector has $\binom{D}{2} = \frac{D^2-D}{2}$ second degree interaction features. A naive
approach to calculating these features is to simply iterate through the combinations of the column indices.
For a sparse vector, many of the resulting interaction features would be zero, and could therefore be ignored.
This work describes a method to efficiently calculate second degree interaction features for a sparse matrix 
that has time and space complexities that decrease quadratically with the density of the input matrix with respect to the naive approach.

\section{Approach}
Let the list of nonzero columns for a given row $\vec{x}$ be denoted by $N_{zc}$. The nonzero second degree 
interaction features are simply the products of all combinations of two elements whose 
columns are in $N_{zc}$. However, to properly place an interaction feature into the correct column, a mapping from the column 
index pairs of $N_{zc}$ into the columns of the interaction matrix is needed. The mapping is 
from pairs $(a, b)$,  where $a$ and $b$ are in $1,2,..., D$, and $a < b$, to $1,2,..., \frac{D^2-D}{2}$,  Such a mapping essentially consists of mapping the indices of entries in the upper triangle of a matrix to indices in a flat 
list. We now describe the construction of such a mapping. 

\subsection{Mapping construction}
We seek a map from matrix indices $(i, j)$ (with $i < j$ and $0 \le i < D$) to numbers $f(i, j)$ with $0 \le f(i, j) < \frac{D(D-1)}{2}$, one that follows the pattern indicated by 
\begin{align}
\begin{bmatrix}
x & 0 & 1 & 2 \\
x & x & 3 & 4 \\
x & x & x & 5 \\
x & x & x & x
\end{bmatrix}
\end{align}
It's considerably easier, however, to consider the same indices, but subtracted from $6$ (or more generally, from $\frac{D(D-1)}{2}$; that gives the pattern
\begin{align}
\label{eq:4x4mat}
\begin{bmatrix}
x & 6 & 5 & 4 \\
x & x & 3 & 2 \\
x & x & x & 1 \\
x & x & x & x
\end{bmatrix}
\end{align}
We'll call the function defined by this example $(i, j) \mapsto g(i, j)$, and then observe that 
\begin{align}
f(i, j) = \frac{D(D-1)}{2} - g(i, j)
\end{align}

To simplify slightly, we introduce a notation for the $n$th triangular number, 
\begin{align}
\begin{bmatrix}
T_2(n) = \frac{n(n+1)}{2}
\end{bmatrix}
\end{align}
\noindent
The subscript $2$ is there to indicate that these are triangles in two dimensions; we'll use $T_3(n)$ to indicate the $n$th tetrahedral number, and so on for higher dimensions. 

The codomain of $g$ is now numbers from $1$ to $T_2(D-1)$, inclusive. 

Observe that in Equation~\ref{eq:4x4mat}, each entry in row $i$ lies in the range
\begin{align}
T_2(D-i-1) &< e \le T_2(D-i).
\end{align}
\noindent
For instance, in row $2$ in our example, where $D = 4$, the entries range from $2$ to $3$, while $T_2(D-i-1) = T_2(1) = 1$ and $T_2(D-i) = T_2(2) = 3$. (Note that row indices start at zero.) Unfortunately, the numbers increase from right to left. The entry in column $j$ is just $T_2(D-i-1) + D-j$, which adds one for the rightmost column (because $D - (D-1) = 1$). 
Thus, the formula for $g$ is simply
\begin{align}
g(i, j) 
&= T_2(D-i-1) + (D-j) \\
&= \frac{(D-i-1)(D-i)}{2} + D-j \\
&= \frac{(D^2 - (2i)D - D - i^2 - i) + 2D - 2j}{2} \\
&= \frac{D^2 - (2i)D + D - i^2 - i - 2j}{2}
\end{align}
and hence 
\begin{align}
f(i, j) 
&= \frac{D(D-1)}{2} - g(i,j) \\
&= \frac{D^2-D}{2} - \frac{D^2 - (2i)D + D - i^2 - i - 2j}{2}\\
&= \frac{D^2-D - D^2 + (2i)D - D + i^2 + i + 2j}{2}\\
&= \frac{(2i)D - 2D + i^2 + i + 2j}{2}
\end{align}
[WRONG]
Correct result:
\begin{align}
R = \frac{ 2in - i^2  + 2j - 3i - 2}{2}.
\end{align}
\subsubsection{Other indices}
With one-based indexing, the formula above becomes
\begin{align}
f_1(i, j) &= ....
\end{align}





  column 


INSERT JOHN'S PROOF HERE

With this mapping, an algorithm for generating second degree interaction features on a 
matrix $A$ can be formulated as follows:

\begin{codebox}
\Procname{$\proc{Sparse Interaction}(A)$}
    \zi $\func{map}(a, b) = \frac{2Da-a^2+2b-3a-2}{2}$
    \zi $N \gets$ row count of $A$
    \zi $D \gets$ column count of $A$
    \zi $B$ $\gets$ Compressed Sparse Row Matrix of size $N \times \frac{D^2-D}{2}$
    \zi \For $\id{row}$ in $A$ \Do
    \zi     $N_{zc} \gets$ nonzero columns of $row$
    \zi     \For $i \gets 0 \To |N_{zc}|-1$ \Do
    \zi         \For $j \gets i+1 \To |N_{zc}|$ \Do
    \zi             $k \gets \func{map}(i, j)$
    \zi             $r \gets$ index of $\id{row}$
    \zi             $B[r, k] \gets \id{row}[i] \cdot \id{row}[j]$
                \End
            \End
       	\End
\end{codebox}

\section{Complexity Analysis}
Assume that A is a matrix with sparsity $0 < d < 1$, $N$ rows, and $D$ columns. Finding 
interaction features with the proposed algorithm has time and space complexity 
$\func{O}(d N D^2)$, 
whereas a naive approach of using non-sparse matrices and multiplying all column 
combinations has time and space complexity $\func{O}(N D^2)$. The algorithm is therefore an 
improvement by a factor of the density factor of $A$.

This can represent a large gain in speed and time. For example, the 20 Newsgroups dataset 
has density $d$ of 0.12 when its unigrams are represented in a vector space model. This 
means the proposed approach would take less than $\frac{1}{8}$ time and memory.

The real benefit of this method is revealed when the average complexity is analysed. The 
number of interactions calculated for a given row are $\binom{|N_{zc}|}{2}$. If the matrix has 
density $d$, then on average, $N_{zc} = D d$, so the number of interaction features 
calculated in total is 

\begin{align*}
N \binom{d D}{2} &= N \frac{(Dd)!}{2!(Dd-2)!}\\
    \\
    &= N \frac{(D^2d^2-Dd)}{2}
\end{align*}

This means that the average complexity decreases quadratically with the density.

\section{Future Work}
The approach for generating second degree interaction features required a mapping from 
combinations of two to the space $1,2,...,\frac{D^2-D}{2}$, which is isomorphic to a mapping from 
the indices of an upper triangular matrix to the indices of a flat list of the same size. 
To generate third degree interaction features, a mapping from combinations of three 
$(a,b,c)$ to the space $1,2,...\frac{D^3-3D^2+2D}{6}$ (which is $\binom{D}{3}$), or the upper $3$-simplex of a tensor to a flat 
list of the same size $\frac{D^3-3D^2+2D}{6}$ would be required. In general, for interaction 
features of degree k, the upper $k$-simplex of a $k$-dimensional tensor must be mapped to the 
space $1,2,...\frac{D!}{k!(D-k)!}$. A similar approach for finding these mappings could be taken 
as the one used here for $k=2$. 

Motivation for deriving mapping functions for higher orders
of interaction features is that the average complexity of generating degree $k$ interaction
features is $N \binom{Dd}{k}$, which decreases polynomially with respect to k compared to
generating the features naively.

    
\vskip 0.2in
\bibliography{sample}

\end{document}